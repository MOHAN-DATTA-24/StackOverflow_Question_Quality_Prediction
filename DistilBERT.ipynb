{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1555593,"sourceType":"datasetVersion","datasetId":850380}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-30T05:33:07.228214Z","iopub.execute_input":"2024-06-30T05:33:07.228576Z","iopub.status.idle":"2024-06-30T05:33:08.221127Z","shell.execute_reply.started":"2024-06-30T05:33:07.228547Z","shell.execute_reply":"2024-06-30T05:33:08.220186Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/60k-stack-overflow-questions-with-quality-rate/valid.csv\n/kaggle/input/60k-stack-overflow-questions-with-quality-rate/train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:33:11.482559Z","iopub.execute_input":"2024-06-30T05:33:11.483010Z","iopub.status.idle":"2024-06-30T05:33:24.769919Z","shell.execute_reply.started":"2024-06-30T05:33:11.482982Z","shell.execute_reply":"2024-06-30T05:33:24.768807Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport torch\nimport os\nfrom bs4 import BeautifulSoup\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom datasets import Dataset\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:33:24.771749Z","iopub.execute_input":"2024-06-30T05:33:24.772064Z","iopub.status.idle":"2024-06-30T05:33:31.309545Z","shell.execute_reply.started":"2024-06-30T05:33:24.772034Z","shell.execute_reply":"2024-06-30T05:33:31.308807Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load DistilBERT tokenizer and model\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n\n# Load data\ndf_train = pd.read_csv('/kaggle/input/60k-stack-overflow-questions-with-quality-rate/train.csv')\ndf_valid = pd.read_csv('/kaggle/input/60k-stack-overflow-questions-with-quality-rate/valid.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:33:35.812341Z","iopub.execute_input":"2024-06-30T05:33:35.813218Z","iopub.status.idle":"2024-06-30T05:33:40.508718Z","shell.execute_reply.started":"2024-06-30T05:33:35.813186Z","shell.execute_reply":"2024-06-30T05:33:40.507598Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6f0626208942eba14374a998316335"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c294929428b4261b3dee7a1f1c0ab89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf5674d9a8874f5bb3669de5bb08b942"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4052f0c758ac46ca8e7890b9ea722f1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"104ad2590e2145c5b34ffad1b561909c"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Preprocess data\ndf_train = df_train.filter(['Title', 'Body', 'Tags', 'Y'])\ndf_train['Y'] = df_train['Y'].map({'LQ_CLOSE':0, 'LQ_EDIT': 1, 'HQ':2})\n\ndf_valid = df_valid.filter(['Title', 'Body', 'Tags', 'Y'])\ndf_valid['Y'] = df_valid['Y'].map({'LQ_CLOSE':0, 'LQ_EDIT': 1, 'HQ':2})","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:33:40.510617Z","iopub.execute_input":"2024-06-30T05:33:40.511353Z","iopub.status.idle":"2024-06-30T05:33:40.545379Z","shell.execute_reply.started":"2024-06-30T05:33:40.511322Z","shell.execute_reply":"2024-06-30T05:33:40.544603Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Preprocess data\nclass Preprocessing:\n    def __get_body_tag_text(self, text):\n        soup = BeautifulSoup(text, features='xml')\n        return soup.get_text()\n\n    def __lower_and_punc_removal(self, text):\n        text = text.lower()\n        text = re.sub(r'[^(a-zA-Z)\\s]', '', text)\n        return text\n\n    def __init__(self, df):\n        self.df = df\n        self.df['Body_Between_Tags'] = self.df['Body'].apply(self.__get_body_tag_text)\n        self.df['Final_clean'] = self.df['Body_Between_Tags'].apply(self.__lower_and_punc_removal)\n\nPreprocessedObject_train = Preprocessing(df=df_train)\nPreprocessedObject_valid = Preprocessing(df=df_valid)\n\nPreprocessedObject_train.df.dropna(inplace=True)\nPreprocessedObject_valid.df.dropna(inplace=True)\nPreprocessedObject_train.df.reset_index(inplace=True)\nPreprocessedObject_valid.df.reset_index(inplace=True)\n\ndf_train_final = PreprocessedObject_train.df\ndf_valid_final = PreprocessedObject_valid.df\n\ndf_train_final.drop(['index', 'Tags', 'Body', 'Title'], inplace=True, axis=1)\ndf_valid_final.drop(['index', 'Tags', 'Body', 'Title'], inplace=True, axis=1)\n\n# Retain the label column\ndf_train_final = df_train_final[['Final_clean', 'Y']]\ndf_valid_final = df_valid_final[['Final_clean', 'Y']]","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:35:01.745509Z","iopub.execute_input":"2024-06-30T05:35:01.746205Z","iopub.status.idle":"2024-06-30T05:35:10.022861Z","shell.execute_reply.started":"2024-06-30T05:35:01.746172Z","shell.execute_reply":"2024-06-30T05:35:10.022070Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/447485124.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  soup = BeautifulSoup(text, features='xml')\n/tmp/ipykernel_34/447485124.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  soup = BeautifulSoup(text, features='xml')\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train_final.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:35:19.444311Z","iopub.execute_input":"2024-06-30T05:35:19.445067Z","iopub.status.idle":"2024-06-30T05:35:19.459030Z","shell.execute_reply.started":"2024-06-30T05:35:19.445033Z","shell.execute_reply":"2024-06-30T05:35:19.457917Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                         Final_clean  Y\n0  im already familiar with repeating tasks every...  0\n1  id like to understand why java  optionals were...  2\n2  i am attempting to overlay a title over an ima...  2\n3  the question is very simple but i just could n...  2\n4  im using custom floatingactionmenu i need to i...  2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Final_clean</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>im already familiar with repeating tasks every...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id like to understand why java  optionals were...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i am attempting to overlay a title over an ima...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the question is very simple but i just could n...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>im using custom floatingactionmenu i need to i...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"'''\ndef collate_fn(batch):\n    # Get input_ids and attention_mask tensors\n    input_ids = [torch.tensor(example[\"input_ids\"]) for example in batch]\n    attention_mask = [torch.tensor(example[\"attention_mask\"]) for example in batch]\n\n    # Pad each sequence to the maximum length\n    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)  # Assuming you have attention masks\n\n    # Check if \"labels\" key exists in examples\n    if \"labels\" in batch[0] and batch[0][\"labels\"] is not None:\n        labels = torch.tensor([example[\"labels\"] for example in batch])\n    else:\n        labels = None  # Set labels to None if not present\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels\n    }\n\n'''\ndef collate_fn(batch):\n    # Get input_ids and attention_mask tensors\n    input_ids = [torch.tensor(example[\"input_ids\"]) for example in batch]\n    attention_mask = [torch.tensor(example[\"attention_mask\"]) for example in batch]\n\n    # Pad each sequence to the maximum length\n    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)  # Assuming you have attention masks\n\n    # Check if \"labels\" key exists in examples\n    if \"labels\" in batch[0] and batch[0][\"labels\"] is not None:\n        labels = torch.tensor([example[\"labels\"] for example in batch])\n    else:\n        labels = None  # Set labels to None if not present\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels\n    }\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:35:28.867225Z","iopub.execute_input":"2024-06-30T05:35:28.867638Z","iopub.status.idle":"2024-06-30T05:35:28.876483Z","shell.execute_reply.started":"2024-06-30T05:35:28.867609Z","shell.execute_reply":"2024-06-30T05:35:28.875505Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Define max_seq_length\nmax_seq_length = 128\ndef tokenize_function(example):\n    # Tokenize the text\n    tokenized_inputs = tokenizer(example['Final_clean'], padding=\"max_length\", truncation=True, max_length=max_seq_length)\n    return tokenized_inputs\n\n# Tokenize datasets\ntokenized_datasets_train = df_train_final.apply(tokenize_function, axis=1)\ntokenized_datasets_valid = df_valid_final.apply(tokenize_function, axis=1)\n\n# Convert tokenized datasets into dictionaries of lists\ntokenized_datasets_train_dict = {\"input_ids\": [], \"attention_mask\": [], \"labels\": []}\nfor tokenized_data, label in zip(tokenized_datasets_train, df_train_final['Y']):\n    tokenized_datasets_train_dict[\"input_ids\"].append(tokenized_data[\"input_ids\"])\n    tokenized_datasets_train_dict[\"attention_mask\"].append(tokenized_data[\"attention_mask\"])\n    tokenized_datasets_train_dict[\"labels\"].append(label)\n\ntokenized_datasets_valid_dict = {\"input_ids\": [], \"attention_mask\": [], \"labels\": []}\nfor tokenized_data, label in zip(tokenized_datasets_valid, df_valid_final['Y']):\n    tokenized_datasets_valid_dict[\"input_ids\"].append(tokenized_data[\"input_ids\"])\n    tokenized_datasets_valid_dict[\"attention_mask\"].append(tokenized_data[\"attention_mask\"])\n    tokenized_datasets_valid_dict[\"labels\"].append(label)\n\n# Convert tokenized datasets into datasets\ntrain_dataset = Dataset.from_dict(tokenized_datasets_train_dict)\nvalid_dataset = Dataset.from_dict(tokenized_datasets_valid_dict)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:35:35.965959Z","iopub.execute_input":"2024-06-30T05:35:35.966338Z","iopub.status.idle":"2024-06-30T05:36:34.787563Z","shell.execute_reply.started":"2024-06-30T05:35:35.966309Z","shell.execute_reply":"2024-06-30T05:36:34.786581Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Define collate function\ndef collate_fn(batch):\n    input_ids = pad_sequence([torch.tensor(example[\"input_ids\"]) for example in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n    attention_mask = pad_sequence([torch.tensor(example[\"attention_mask\"]) for example in batch], batch_first=True, padding_value=0)\n    labels = torch.tensor([example[\"labels\"] for example in batch])\n    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n\n# Create DataLoader\ntrain_dataloader = DataLoader(train_dataset, batch_size=4, collate_fn=collate_fn)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=4, collate_fn=collate_fn)\n\n# Move model to appropriate device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:36:39.440097Z","iopub.execute_input":"2024-06-30T05:36:39.440449Z","iopub.status.idle":"2024-06-30T05:36:39.697801Z","shell.execute_reply.started":"2024-06-30T05:36:39.440423Z","shell.execute_reply":"2024-06-30T05:36:39.696812Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Define optimizer and scheduler\nfrom transformers import AdamW, get_scheduler\noptimizer = AdamW(model.parameters(), lr=5e-5)\nnum_epochs = 1\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:36:43.109490Z","iopub.execute_input":"2024-06-30T05:36:43.110015Z","iopub.status.idle":"2024-06-30T05:36:43.129502Z","shell.execute_reply.started":"2024-06-30T05:36:43.109982Z","shell.execute_reply":"2024-06-30T05:36:43.128635Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tqdm\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:41:28.798223Z","iopub.execute_input":"2024-06-30T05:41:28.798614Z","iopub.status.idle":"2024-06-30T05:41:41.052859Z","shell.execute_reply.started":"2024-06-30T05:41:28.798585Z","shell.execute_reply":"2024-06-30T05:41:41.051647Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fine-tuning loop\nfrom tqdm import tqdm\nimport torch\n\nnum_training_steps = 1  # Adjust as needed\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n\nmodel.train()\n\n# Progress bar for the training loop\nfor epoch in range(num_training_steps):\n    print(f\"Epoch {epoch+1}/{num_training_steps}\")\n    epoch_iterator = tqdm(train_dataloader, desc=\"Training\", leave=True)\n    for batch in epoch_iterator:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n        # Update progress bar with loss value\n        epoch_iterator.set_postfix(loss=loss.item())\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:42:06.201544Z","iopub.execute_input":"2024-06-30T05:42:06.202477Z","iopub.status.idle":"2024-06-30T05:49:40.687959Z","shell.execute_reply.started":"2024-06-30T05:42:06.202440Z","shell.execute_reply":"2024-06-30T05:49:40.687041Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/1\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 11250/11250 [07:34<00:00, 24.75it/s, loss=0.296]  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation\ncorrect = 0\ntotal = 0\nmodel.eval()\nfor batch in valid_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    correct += torch.sum(predictions == batch[\"labels\"]).item()\n    total += len(predictions)\n\naccuracy = correct / total\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:50:10.824330Z","iopub.execute_input":"2024-06-30T05:50:10.825270Z","iopub.status.idle":"2024-06-30T05:50:49.908408Z","shell.execute_reply.started":"2024-06-30T05:50:10.825235Z","shell.execute_reply":"2024-06-30T05:50:49.907444Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Accuracy: 0.8137333333333333\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-06-30T05:51:19.367318Z","iopub.execute_input":"2024-06-30T05:51:19.367700Z","iopub.status.idle":"2024-06-30T05:51:32.140938Z","shell.execute_reply.started":"2024-06-30T05:51:19.367671Z","shell.execute_reply":"2024-06-30T05:51:32.139847Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.19.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nimport matplotlib.pyplot as plt\n\n# Initialize the metrics\naccuracy_metric = evaluate.load(\"accuracy\")\nf1_metric = evaluate.load(\"f1\")\nprecision_metric = evaluate.load(\"precision\")\nrecall_metric = evaluate.load(\"recall\")\n\nmodel.eval()\n\n# Evaluate the model on the evaluation dataset\nfor batch in valid_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n\n    # Add batch results to the metrics\n    accuracy_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n    f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n    precision_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n    recall_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\n# Compute the metrics\naccuracy = accuracy_metric.compute()['accuracy']\nf1 = f1_metric.compute(average='weighted')['f1']\nprecision = precision_metric.compute(average='weighted')['precision']\nrecall = recall_metric.compute(average='weighted')['recall']\n\n# Store the metrics in a dictionary for easy plotting\nmetrics = {\n    'Accuracy': accuracy,\n    'F1 Score': f1,\n    'Precision': precision,\n    'Recall': recall\n}\n\n# Colors for the bars\ncolors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # You can customize these colors\n\n# Plot the metrics as a bar chart\nplt.figure(figsize=(10, 5))\nbars = plt.bar(metrics.keys(), metrics.values(), color=colors)\nplt.xlabel('Metrics')\nplt.ylabel('Scores')\nplt.title('Evaluation Metrics')\nplt.ylim(0, 1)  # Assuming metrics are between 0 and 1\n\n# Add values on top of the bars for better visualization\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 4), va='bottom')  # va: vertical alignment\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:01:25.099711Z","iopub.execute_input":"2024-06-30T06:01:25.100120Z","iopub.status.idle":"2024-06-30T06:02:14.848022Z","shell.execute_reply.started":"2024-06-30T06:01:25.100091Z","shell.execute_reply":"2024-06-30T06:02:14.847104Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n# Metrics data\nmetrics_data = {\n    'Metric': ['Accuracy', 'F1 Score', 'Precision', 'Recall'],\n    'Score': [accuracy, f1, precision, recall]\n}\n\n# Create DataFrame\nmetrics_df = pd.DataFrame(metrics_data)\n\n# Save to CSV in Kaggle environment\nmetrics_df.to_csv('metrics_distilbert.csv', index=False)\n\n# Download the CSV file to your local machine\nfrom IPython.display import FileLink\nFileLink(r'metrics_distilbert.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:04:14.033874Z","iopub.execute_input":"2024-06-30T06:04:14.034847Z","iopub.status.idle":"2024-06-30T06:04:14.047134Z","shell.execute_reply.started":"2024-06-30T06:04:14.034803Z","shell.execute_reply":"2024-06-30T06:04:14.046259Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/metrics_distilbert.csv","text/html":"<a href='metrics_distilbert.csv' target='_blank'>metrics_distilbert.csv</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"import json\n\n# Assuming `metrics` is a dictionary containing your metrics\nmetrics = {\n    'Accuracy': accuracy,\n    'F1 Score': f1,\n    'Precision': precision,\n    'Recall': recall\n}\n\n# Save the metrics to a JSON file in Kaggle environment\nmetrics_filename = 'metrics_distilbert.json'\nwith open(metrics_filename, 'w') as f:\n    json.dump(metrics, f)\n\n# Download the JSON file to your local machine\nfrom IPython.display import FileLink\nFileLink(r'metrics_distilbert.json')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:04:38.802321Z","iopub.execute_input":"2024-06-30T06:04:38.802697Z","iopub.status.idle":"2024-06-30T06:04:38.810896Z","shell.execute_reply.started":"2024-06-30T06:04:38.802667Z","shell.execute_reply":"2024-06-30T06:04:38.809994Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/metrics_distilbert.json","text/html":"<a href='metrics_distilbert.json' target='_blank'>metrics_distilbert.json</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\n# Assuming `model` is your trained model\n# Save the model's state dictionary to a file in Kaggle environment\nmodel_path = 'trained_model_distilbert.pth'\ntorch.save(model.state_dict(), model_path)\n\n# Download the model file to your local machine\nfrom IPython.display import FileLink\nFileLink(r'trained_model_distilbert.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:05:03.365658Z","iopub.execute_input":"2024-06-30T06:05:03.366040Z","iopub.status.idle":"2024-06-30T06:05:03.791149Z","shell.execute_reply.started":"2024-06-30T06:05:03.366009Z","shell.execute_reply":"2024-06-30T06:05:03.790216Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/trained_model_distilbert.pth","text/html":"<a href='trained_model_distilbert.pth' target='_blank'>trained_model_distilbert.pth</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install gradio","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:16:51.352074Z","iopub.execute_input":"2024-06-30T06:16:51.352994Z","iopub.status.idle":"2024-06-30T06:17:12.034690Z","shell.execute_reply.started":"2024-06-30T06:16:51.352955Z","shell.execute_reply":"2024-06-30T06:17:12.033513Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-4.37.2-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.3.0)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.108.0)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client==1.0.2 (from gradio)\n  Downloading gradio_client-1.0.2-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.23.2)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.1.1)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.5)\nRequirement already satisfied: numpy<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.10)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.1)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (9.5.0)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.5.3)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.9 (from gradio)\n  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.1)\nCollecting ruff>=0.2.2 (from gradio)\n  Downloading ruff-0.5.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting tomlkit==0.12.0 (from gradio)\n  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting typer<1.0,>=0.12 (from gradio)\n  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.9.0)\nCollecting urllib3~=2.0 (from gradio)\n  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.0.2->gradio) (2024.3.1)\nCollecting websockets<12.0,>=10.0 (from gradio-client==1.0.2->gradio)\n  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.14.6)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.0)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.32.0.post1)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.16.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-4.37.2-py3-none-any.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.0.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.2/318.2 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\nDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\nDownloading ruff-0.5.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=ccf880628f9304d2d62d15171a150422baa1c4035e564e3e8e29dacc7045c202\n  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\nSuccessfully built ffmpy\nInstalling collected packages: ffmpy, websockets, urllib3, tomlkit, semantic-version, ruff, python-multipart, typer, gradio-client, gradio\n  Attempting uninstall: websockets\n    Found existing installation: websockets 12.0\n    Uninstalling websockets-12.0:\n      Successfully uninstalled websockets-12.0\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: tomlkit\n    Found existing installation: tomlkit 0.12.5\n    Uninstalling tomlkit-0.12.5:\n      Successfully uninstalled tomlkit-0.12.5\n  Attempting uninstall: typer\n    Found existing installation: typer 0.9.0\n    Uninstalling typer-0.9.0:\n      Successfully uninstalled typer-0.9.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\nspacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nweasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ffmpy-0.3.2 gradio-4.37.2 gradio-client-1.0.2 python-multipart-0.0.9 ruff-0.5.0 semantic-version-2.10.0 tomlkit-0.12.0 typer-0.12.3 urllib3-2.1.0 websockets-11.0.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import BertForSequenceClassification, BertTokenizer\nimport gradio as gr\n\n# Load the model architecture\nmodel = BertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)  # Adjust num_labels based on your task\n\n# Load the saved weights\nmodel_path = '/kaggle/working/trained_model_distilbert.pth'\n\n# Load state_dict and check for missing keys\nstate_dict = torch.load(model_path, map_location=torch.device(\"cpu\"))\nmissing_keys = []\nfor key in list(state_dict.keys()):\n    if key not in model.state_dict():\n        missing_keys.append(key)\n        state_dict.pop(key)\n\nif missing_keys:\n    print(f\"Warning: Missing keys in state_dict: {missing_keys}\")\n\n# Load the state_dict into the model\nmodel.load_state_dict(state_dict, strict=False)\n\n# Tokenizer for preprocessing input\ntokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased')\n\n# Define a function to make predictions\ndef predict(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    logits = outputs.logits\n    predicted_class = torch.argmax(logits, dim=1).item()\n    return predicted_class\n\n# Create a Gradio interface\niface = gr.Interface(\n    fn=predict,\n    inputs=gr.Textbox(lines=2, label=\"Input Text\"),\n    outputs=gr.Label(num_top_classes=3),\n    title=\"DistilBERT Text Classification\",\n    description=\"Enter text to classify into one of three categories.\",\n)\n\n# Launch the interface\niface.launch()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:18:19.917352Z","iopub.execute_input":"2024-06-30T06:18:19.917735Z","iopub.status.idle":"2024-06-30T06:18:25.490222Z","shell.execute_reply.started":"2024-06-30T06:18:19.917706Z","shell.execute_reply":"2024-06-30T06:18:25.489309Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nThe tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \nThe class this function is called from is 'BertTokenizer'.\n","output_type":"stream"},{"name":"stdout","text":"Warning: Missing keys in state_dict: ['distilbert.embeddings.word_embeddings.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'pre_classifier.weight', 'pre_classifier.bias']\nRunning on local URL:  http://127.0.0.1:7860\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\nRunning on public URL: https://91f59b2d5045db0346.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://91f59b2d5045db0346.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}